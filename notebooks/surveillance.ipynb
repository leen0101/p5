{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook : √âvaluation du mod√®le sur diff√©rentes p√©riodes\n",
    "charge un mod√®le de machine learning sauvegard√© dans MLflow, √©value les performances du mod√®le sur deux p√©riodes distinctes. Les r√©sultats sont ensuite enregistr√©s dans MLflow.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importation des biblioth√®ques n√©cessaires et configuration mlflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='gs://apip5bucket/artifacts/1', creation_time=1728821200655, experiment_id='1', last_update_time=1728821200655, lifecycle_stage='active', name='Text_Processing_Experiment', tags={}>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configure MLflow\n",
    "mlflow.set_tracking_uri(\"https://mlflowp51-975919512217.us-central1.run.app\")\n",
    "mlflow.set_experiment(\"Text_Processing_Experiment\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artefacts\n",
    "Charge les artefacts stock√©s dans MLflow (Mod√®les et donn√©es).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charge les artefacts (mod√®les et donn√©es)\n",
    "def load_mlflow_artifact(artifact_path):\n",
    "    local_path = mlflow.artifacts.download_artifacts(artifact_path)\n",
    "    with open(local_path, 'rb') as f:\n",
    "        return joblib.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# Mod√®les et les artefacts\n",
    "X_reduced = load_mlflow_artifact(\"mlflow_artifacts/X_reduced.pkl\")\n",
    "y = load_mlflow_artifact(\"mlflow_artifacts/y.pkl\")\n",
    "model_path = \"mlflow_artifacts/bow_svd_model.h5\"\n",
    "\n",
    "# Mod√®le depuis MLflow\n",
    "model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "# Compile le mod√®le\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S√©paration des donn√©es en deux p√©riodes (premiers 6 mois et derniers 6 mois)\n",
    "Divise les donn√©es en deux p√©riodes : janvier √† juin 2023 (premi√®re p√©riode) et juillet √† d√©cembre 2023 (deuxi√®me p√©riode).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Donn√©es pour la p√©riode de surveillance\n",
    "df = pd.read_csv('db/cleaned_data_sample.csv')\n",
    "df['CreationDate'] = pd.to_datetime(df['CreationDate'])\n",
    "\n",
    "# Divise les donn√©es en p√©riodes\n",
    "df_first_half = df[(df['CreationDate'] >= '2023-01-01') & (df['CreationDate'] < '2023-07-01')]\n",
    "df_second_half = df[(df['CreationDate'] >= '2023-07-01') & (df['CreationDate'] <= '2023-12-31')]\n",
    "\n",
    "# S√©pare X et y pour chaque p√©riode\n",
    "X_first_half = X_reduced[:len(df_first_half)]\n",
    "X_second_half = X_reduced[len(df_first_half):]\n",
    "y_first_half = y[:len(df_first_half)]\n",
    "y_second_half = y[len(df_first_half):]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/13 14:22:12 INFO mlflow.tracking._tracking_service.client: üèÉ View run Descriptive Statistics first_half_2023 at: https://mlflowp51-975919512217.us-central1.run.app/#/experiments/1/runs/3c9e656644754c288b365b64a556721e.\n",
      "2024/10/13 14:22:12 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: https://mlflowp51-975919512217.us-central1.run.app/#/experiments/1.\n"
     ]
    },
    {
     "ename": "RestException",
     "evalue": "INVALID_PARAMETER_VALUE: Invalid metric name: 'first_half_2023_Id_25%'. Names may only contain alphanumerics, underscores (_), dashes (-), periods (.), spaces ( ), and slashes (/).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRestException\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStatistiques descriptives pour \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mperiod_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m enregistr√©es dans MLflow.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Calcule et enregistre les statistiques descriptives pour les deux p√©riodes\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[43mlog_descriptive_statistics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_first_half\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfirst_half_2023\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m log_descriptive_statistics(df_second_half, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msecond_half_2023\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[6], line 9\u001b[0m, in \u001b[0;36mlog_descriptive_statistics\u001b[1;34m(df, period_name)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m descriptive_stats\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[0;32m      8\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m stat \u001b[38;5;129;01min\u001b[39;00m descriptive_stats\u001b[38;5;241m.\u001b[39mindex:\n\u001b[1;32m----> 9\u001b[0m             \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_metric\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mperiod_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcol\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mstat\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescriptive_stats\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStatistiques descriptives pour \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mperiod_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m enregistr√©es dans MLflow.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\leenc\\Documents\\openclassrooms\\p5\\.venv\\Lib\\site-packages\\mlflow\\tracking\\fluent.py:872\u001b[0m, in \u001b[0;36mlog_metric\u001b[1;34m(key, value, step, synchronous, timestamp, run_id)\u001b[0m\n\u001b[0;32m    870\u001b[0m run_id \u001b[38;5;241m=\u001b[39m run_id \u001b[38;5;129;01mor\u001b[39;00m _get_or_start_run()\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mrun_id\n\u001b[0;32m    871\u001b[0m synchronous \u001b[38;5;241m=\u001b[39m synchronous \u001b[38;5;28;01mif\u001b[39;00m synchronous \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m MLFLOW_ENABLE_ASYNC_LOGGING\u001b[38;5;241m.\u001b[39mget()\n\u001b[1;32m--> 872\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mMlflowClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_metric\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    873\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimestamp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mget_current_time_millis\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m    \u001b[49m\u001b[43msynchronous\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynchronous\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\leenc\\Documents\\openclassrooms\\p5\\.venv\\Lib\\site-packages\\mlflow\\tracking\\client.py:1517\u001b[0m, in \u001b[0;36mMlflowClient.log_metric\u001b[1;34m(self, run_id, key, value, timestamp, step, synchronous)\u001b[0m\n\u001b[0;32m   1444\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1445\u001b[0m \u001b[38;5;124;03mLog a metric against the run ID.\u001b[39;00m\n\u001b[0;32m   1446\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1512\u001b[0m \u001b[38;5;124;03m    status: FINISHED\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1514\u001b[0m synchronous \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1515\u001b[0m     synchronous \u001b[38;5;28;01mif\u001b[39;00m synchronous \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m MLFLOW_ENABLE_ASYNC_LOGGING\u001b[38;5;241m.\u001b[39mget()\n\u001b[0;32m   1516\u001b[0m )\n\u001b[1;32m-> 1517\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tracking_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_metric\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1518\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimestamp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msynchronous\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynchronous\u001b[49m\n\u001b[0;32m   1519\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\leenc\\Documents\\openclassrooms\\p5\\.venv\\Lib\\site-packages\\mlflow\\tracking\\_tracking_service\\client.py:564\u001b[0m, in \u001b[0;36mTrackingServiceClient.log_metric\u001b[1;34m(self, run_id, key, value, timestamp, step, synchronous)\u001b[0m\n\u001b[0;32m    562\u001b[0m metric \u001b[38;5;241m=\u001b[39m Metric(key, metric_value, timestamp, step)\n\u001b[0;32m    563\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synchronous:\n\u001b[1;32m--> 564\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_metric\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    565\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    566\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstore\u001b[38;5;241m.\u001b[39mlog_metric_async(run_id, metric)\n",
      "File \u001b[1;32mc:\\Users\\leenc\\Documents\\openclassrooms\\p5\\.venv\\Lib\\site-packages\\mlflow\\store\\tracking\\rest_store.py:404\u001b[0m, in \u001b[0;36mRestStore.log_metric\u001b[1;34m(self, run_id, metric)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;124;03mLog a metric for the specified run\u001b[39;00m\n\u001b[0;32m    389\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    392\u001b[0m \u001b[38;5;124;03m    metric: Metric instance to log\u001b[39;00m\n\u001b[0;32m    393\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    394\u001b[0m req_body \u001b[38;5;241m=\u001b[39m message_to_json(\n\u001b[0;32m    395\u001b[0m     LogMetric(\n\u001b[0;32m    396\u001b[0m         run_uuid\u001b[38;5;241m=\u001b[39mrun_id,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    402\u001b[0m     )\n\u001b[0;32m    403\u001b[0m )\n\u001b[1;32m--> 404\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_endpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mLogMetric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq_body\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\leenc\\Documents\\openclassrooms\\p5\\.venv\\Lib\\site-packages\\mlflow\\store\\tracking\\rest_store.py:82\u001b[0m, in \u001b[0;36mRestStore._call_endpoint\u001b[1;34m(self, api, json_body, endpoint)\u001b[0m\n\u001b[0;32m     80\u001b[0m     endpoint, method \u001b[38;5;241m=\u001b[39m _METHOD_TO_INFO[api]\n\u001b[0;32m     81\u001b[0m response_proto \u001b[38;5;241m=\u001b[39m api\u001b[38;5;241m.\u001b[39mResponse()\n\u001b[1;32m---> 82\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_endpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_host_creds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_proto\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\leenc\\Documents\\openclassrooms\\p5\\.venv\\Lib\\site-packages\\mlflow\\utils\\rest_utils.py:370\u001b[0m, in \u001b[0;36mcall_endpoint\u001b[1;34m(host_creds, endpoint, method, json_body, response_proto, extra_headers)\u001b[0m\n\u001b[0;32m    367\u001b[0m     call_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjson\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m json_body\n\u001b[0;32m    368\u001b[0m     response \u001b[38;5;241m=\u001b[39m http_request(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcall_kwargs)\n\u001b[1;32m--> 370\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mverify_rest_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    371\u001b[0m response_to_parse \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mtext\n\u001b[0;32m    372\u001b[0m js_dict \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(response_to_parse)\n",
      "File \u001b[1;32mc:\\Users\\leenc\\Documents\\openclassrooms\\p5\\.venv\\Lib\\site-packages\\mlflow\\utils\\rest_utils.py:240\u001b[0m, in \u001b[0;36mverify_rest_response\u001b[1;34m(response, endpoint)\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _can_parse_as_json_object(response\u001b[38;5;241m.\u001b[39mtext):\n\u001b[1;32m--> 240\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m RestException(json\u001b[38;5;241m.\u001b[39mloads(response\u001b[38;5;241m.\u001b[39mtext))\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    242\u001b[0m         base_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    243\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAPI request to endpoint \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mendpoint\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    244\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfailed with error code \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m != 200\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    245\u001b[0m         )\n",
      "\u001b[1;31mRestException\u001b[0m: INVALID_PARAMETER_VALUE: Invalid metric name: 'first_half_2023_Id_25%'. Names may only contain alphanumerics, underscores (_), dashes (-), periods (.), spaces ( ), and slashes (/)."
     ]
    }
   ],
   "source": [
    "def log_descriptive_statistics(df, period_name):\n",
    "    \"\"\"Calcule et enregistre les statistiques descriptives des colonnes num√©riques, avec des noms valides pour MLflow.\"\"\"\n",
    "    numeric_columns = df.select_dtypes(include=[np.number]).columns\n",
    "    descriptive_stats = df[numeric_columns].describe()\n",
    "\n",
    "    # Normaliser les noms pour MLflow (enlever les caract√®res non autoris√©s)\n",
    "    valid_stats = descriptive_stats.rename(index=lambda x: x.replace('%', 'percent').replace(' ', '_'))\n",
    "\n",
    "    # Enregistrer les statistiques dans MLflow\n",
    "    with mlflow.start_run(run_name=f\"Descriptive Statistics {period_name}\"):\n",
    "        for col in valid_stats.columns:\n",
    "            for stat in valid_stats.index:\n",
    "                metric_name = f\"{period_name}_{col}_{stat}\"\n",
    "                mlflow.log_metric(metric_name, valid_stats.loc[stat, col])\n",
    "\n",
    "    print(f\"Statistiques descriptives pour {period_name} enregistr√©es dans MLflow.\")\n",
    "\n",
    "# Calculer et enregistrer les statistiques descriptives pour les deux p√©riodes\n",
    "log_descriptive_statistics(df_first_half, \"first_half_2023\")\n",
    "log_descriptive_statistics(df_second_half, \"second_half_2023\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## √âvaluation du mod√®le sans r√©entra√Ænement\n",
    "\n",
    "Cette fonction √©value les performances du mod√®le sans le r√©entra√Æner sur les deux p√©riodes (data drift et model drift).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# √âvaluation du mod√®le sans r√©entra√Ænement pour chaque p√©riode\n",
    "def evaluate_model(model, X_test, y_test, dataset_name):\n",
    "    \"\"\"√âvalue les performances du mod√®le, y compris la perte, sans le r√©entra√Æner.\"\"\"\n",
    "    # Pr√©dictions du mod√®le\n",
    "    loss, accuracy = model.evaluate(X_test, y_test, verbose=0)  # Ajout de la perte lors de l'√©valuation\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = (y_pred > 0.5).astype(\"int32\")\n",
    "    \n",
    "    # Calcul des m√©triques\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    # Enregistrement des r√©sultats dans MLflow\n",
    "    with mlflow.start_run(run_name=f\"Model Evaluation {dataset_name}\"):\n",
    "        mlflow.log_metric(f\"{dataset_name}_loss\", loss)\n",
    "        mlflow.log_metric(f\"{dataset_name}_accuracy\", accuracy)\n",
    "        mlflow.log_metric(f\"{dataset_name}_f1_score\", f1)\n",
    "        mlflow.log_metric(f\"{dataset_name}_precision\", precision)\n",
    "        mlflow.log_metric(f\"{dataset_name}_recall\", recall)\n",
    "\n",
    "    print(f\"{dataset_name} - Loss: {loss}, Accuracy: {accuracy}, F1 Score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## √âvaluation du mod√®le sur les deux semestres d'un an (Data Drift et Model Drift)\n",
    "Compare les performances du mod√®le sur les deux p√©riodes pour d√©tecter les d√©rives de donn√©es et de mod√®le.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m499/499\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/13 14:06:44 INFO mlflow.tracking._tracking_service.client: üèÉ View run Model Evaluation first_half_2023 at: https://mlflowp51-975919512217.us-central1.run.app/#/experiments/1/runs/7f9e997515a843378ff0cbe9f8e49ccc.\n",
      "2024/10/13 14:06:44 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: https://mlflowp51-975919512217.us-central1.run.app/#/experiments/1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first_half_2023 - Accuracy: 0.38625963768570176, F1 Score: 0.46978230124867953\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 875us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\leenc\\Documents\\openclassrooms\\p5\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "2024/10/13 14:06:45 INFO mlflow.tracking._tracking_service.client: üèÉ View run Model Evaluation second_half_2023 at: https://mlflowp51-975919512217.us-central1.run.app/#/experiments/1/runs/8d48cc8ea246474db8030ea10020c9f1.\n",
      "2024/10/13 14:06:45 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: https://mlflowp51-975919512217.us-central1.run.app/#/experiments/1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "second_half_2023 - Accuracy: 0.3811188811188811, F1 Score: 0.45644860539824234\n",
      "√âvaluation du mod√®le enregistr√©e dans MLflow.\n"
     ]
    }
   ],
   "source": [
    "# Performances pour chaque p√©riode sans r√©entra√Ænement\n",
    "evaluate_model(model, X_first_half, y_first_half, \"first_half_2023\")\n",
    "evaluate_model(model, X_second_half, y_second_half, \"second_half_2023\")\n",
    "\n",
    "# Affichage des r√©sultats\n",
    "print(\"√âvaluation du mod√®le enregistr√©e dans MLflow.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
