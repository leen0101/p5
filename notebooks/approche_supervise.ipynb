{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook pour l'approche supervisée\n",
    "Ce notebook contient la génération de trois modèles, BoW, Word2Vec et use sentence encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import logging\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n",
    "import tensorflow_hub as hub\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/13 00:31:36 INFO mlflow.tracking.fluent: Experiment with name 'Text_Processing_Experiment' does not exist. Creating a new experiment.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Variables d'environnement et configuration MLflow\n",
    "load_dotenv()\n",
    "tracking_uri = \"https://mlflowp51-975919512217.us-central1.run.app\"\n",
    "mlflow.set_tracking_uri(tracking_uri)\n",
    "mlflow.set_experiment(\"Text_Processing_Experiment\")\n",
    "\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"f8bc1d91ca98.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les artefacts X et y ont été chargés avec succès depuis MLflow.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def load_mlflow_artifact(artifact_path):\n",
    "    local_path = mlflow.artifacts.download_artifacts(artifact_path)\n",
    "    with open(local_path, 'rb') as f:\n",
    "        return joblib.load(f)\n",
    "\n",
    "# X et y sauvegardés dans MLflow\n",
    "X_reduced = load_mlflow_artifact(\"mlflow_artifacts/X_reduced.pkl\")\n",
    "X_word2vec = load_mlflow_artifact(\"mlflow_artifacts/X_word2vec.pkl\")\n",
    "X_use_np = load_mlflow_artifact(\"mlflow_artifacts/X_use_embeddings.pkl\")\n",
    "y = load_mlflow_artifact(\"mlflow_artifacts/y.pkl\")\n",
    "\n",
    "print(\"Les artefacts X et y ont été chargés avec succès depuis MLflow.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_model_objects():\n",
    "    with open('mlflow_artifacts/vectorizer.pkl', 'rb') as f:\n",
    "        vectorizer = joblib.load(f)\n",
    "    with open('mlflow_artifacts/svd.pkl', 'rb') as f:\n",
    "        svd = joblib.load(f)\n",
    "    with open('mlflow_artifacts/top_tags.pkl', 'rb') as f:\n",
    "        top_tags = joblib.load(f)\n",
    "    return vectorizer, svd, top_tags\n",
    "\n",
    "vectorizer, svd, top_tags = load_model_objects()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_model(input_shape, output_shape):\n",
    "    model = Sequential([\n",
    "    Dense(256, activation='relu', input_shape=(input_shape,)),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(output_shape, activation='sigmoid') \n",
    "    ])\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_model(model, X_train, y_train, X_val, y_val, epochs=10):\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    history = model.fit(X_train, y_train, epochs=epochs, batch_size=32,\n",
    "                        validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    loss, accuracy = model.evaluate(X_test, y_test)\n",
    "    print(f\"Loss: {loss}, Accuracy: {accuracy}\")\n",
    "    return loss, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def transform_text_to_bow(text, vectorizer, svd):\n",
    "    X_bow = vectorizer.transform([text])\n",
    "    return svd.transform(X_bow)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le modèle Word2Vec a été rechargé et sauvegardé sous: mlflow_artifacts/new_word2vec_model.model\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def transform_text_to_word2vec(text, word2vec_model):\n",
    "    tokens = text.split()\n",
    "    word_vectors = [word2vec_model.wv[word] for word in tokens if word in word2vec_model.wv]\n",
    "    if word_vectors:\n",
    "        return np.mean(word_vectors, axis=0).reshape(1, -1)  \n",
    "    else:\n",
    "        return np.zeros((1, 300)) \n",
    "# Réenregistrer le modèle Word2Vec pour garantir la compatibilité\n",
    "def reload_and_save_word2vec_model(model_path, new_model_path):\n",
    "    # Charge l'ancien modèle\n",
    "    word2vec_model = Word2Vec.load(model_path)\n",
    "\n",
    "    # Sauvegarde le modèle avec la version actuelle de gensim\n",
    "    word2vec_model.save(new_model_path)\n",
    "\n",
    "    print(f\"Le modèle Word2Vec a été rechargé et sauvegardé sous: {new_model_path}\")\n",
    "    return word2vec_model\n",
    "\n",
    "# Appele la fonction pour réenregistrer le modèle\n",
    "new_word2vec_model_path = \"mlflow_artifacts/new_word2vec_model.model\"\n",
    "word2vec_model = reload_and_save_word2vec_model(\"mlflow_artifacts/word2vec_model.model\", new_word2vec_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def transform_text_to_use(text):\n",
    "    try:\n",
    "        use_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\", trainable=False)\n",
    "        input_tensor = tf.convert_to_tensor([text], dtype=tf.string)\n",
    "        embeddings = use_layer(input_tensor)\n",
    "        embeddings_np = embeddings.numpy()\n",
    "        logging.info(f\"Embeddings générés pour le texte '{text}': {embeddings_np}\")\n",
    "        return embeddings_np\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Erreur lors de la transformation du texte en embeddings USE : {str(e)}\")\n",
    "        raise e\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model BOW avec entrée données traitées par BoW + SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\leenc\\Documents\\openclassrooms\\p5\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 0.4680 - val_accuracy: 0.3597 - val_loss: 0.2335\n",
      "Epoch 2/10\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2987 - loss: 0.2538 - val_accuracy: 0.4494 - val_loss: 0.1936\n",
      "Epoch 3/10\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3873 - loss: 0.2094 - val_accuracy: 0.4654 - val_loss: 0.1770\n",
      "Epoch 4/10\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4216 - loss: 0.1965 - val_accuracy: 0.4859 - val_loss: 0.1687\n",
      "Epoch 5/10\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4431 - loss: 0.1804 - val_accuracy: 0.5125 - val_loss: 0.1616\n",
      "Epoch 6/10\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4689 - loss: 0.1740 - val_accuracy: 0.5171 - val_loss: 0.1581\n",
      "Epoch 7/10\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4814 - loss: 0.1684 - val_accuracy: 0.5072 - val_loss: 0.1546\n",
      "Epoch 8/10\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5118 - loss: 0.1609 - val_accuracy: 0.5202 - val_loss: 0.1536\n",
      "Epoch 9/10\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5065 - loss: 0.1541 - val_accuracy: 0.5240 - val_loss: 0.1512\n",
      "Epoch 10/10\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5093 - loss: 0.1528 - val_accuracy: 0.5232 - val_loss: 0.1495\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 634us/step - accuracy: 0.5164 - loss: 0.1450\n",
      "Loss: 0.1494912952184677, Accuracy: 0.523193895816803\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Modèle BoW + SVD\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reduced, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model_bow_svd = build_model(X_train.shape[1], y_train.shape[1])\n",
    "\n",
    "# Entraînement et évaluation du modèle BoW + SVD\n",
    "history_bow_svd = train_model(model_bow_svd, X_train, y_train, X_test, y_test)\n",
    "loss_bow_svd, accuracy_bow_svd = evaluate_model(model_bow_svd, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Run with UUID 632c8cb2004f4f76aac4701f30b3e6d0 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Suivi dans MLflow\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBoW+SVD Model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[0;32m      3\u001b[0m     mlflow\u001b[38;5;241m.\u001b[39mlog_param(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmlflow_artifacts\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBoW+SVD\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m     mlflow\u001b[38;5;241m.\u001b[39mlog_metric(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m, loss_bow_svd)\n",
      "File \u001b[1;32mc:\\Users\\leenc\\Documents\\openclassrooms\\p5\\.venv\\Lib\\site-packages\\mlflow\\tracking\\fluent.py:321\u001b[0m, in \u001b[0;36mstart_run\u001b[1;34m(run_id, experiment_id, run_name, nested, parent_run_id, tags, description, log_system_metrics)\u001b[0m\n\u001b[0;32m    319\u001b[0m experiment_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(experiment_id) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(experiment_id, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m experiment_id\n\u001b[0;32m    320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(_active_run_stack) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m nested:\n\u001b[1;32m--> 321\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\n\u001b[0;32m    322\u001b[0m         (\n\u001b[0;32m    323\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRun with UUID \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m is already active. To start a new run, first end the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    324\u001b[0m             \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcurrent run with mlflow.end_run(). To start a nested \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    325\u001b[0m             \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun, call start_run with nested=True\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    326\u001b[0m         )\u001b[38;5;241m.\u001b[39mformat(_active_run_stack[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mrun_id)\n\u001b[0;32m    327\u001b[0m     )\n\u001b[0;32m    328\u001b[0m client \u001b[38;5;241m=\u001b[39m MlflowClient()\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_id:\n",
      "\u001b[1;31mException\u001b[0m: Run with UUID 632c8cb2004f4f76aac4701f30b3e6d0 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True"
     ]
    }
   ],
   "source": [
    "\n",
    "# Suivi dans MLflow\n",
    "with mlflow.start_run(run_name=\"BoW+SVD Model\"):\n",
    "    mlflow.log_param(\"mlflow_artifacts\", \"BoW+SVD\")\n",
    "    mlflow.log_metric(\"loss\", loss_bow_svd)\n",
    "    mlflow.log_metric(\"accuracy\", accuracy_bow_svd)\n",
    "\n",
    "    # Sauvegarde du modèle en .h5\n",
    "    model_bow_svd_path = os.path.join(\"mlflow_artifacts\", 'bow_svd_model.h5')\n",
    "    model_bow_svd.save(model_bow_svd_path)\n",
    "    \n",
    "    # Suivi dans MLflow\n",
    "    mlflow.keras.log_model(model=model_bow_svd, artifact_path=\"bow_svd_model\")\n",
    "    mlflow.log_artifact(model_bow_svd_path)  # Enregistre le fichier .h5 dans MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\leenc\\Documents\\openclassrooms\\p5\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.2342 - loss: 0.2832 - val_accuracy: 0.5204 - val_loss: 0.1491\n",
      "Epoch 2/10\n",
      "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4461 - loss: 0.1661 - val_accuracy: 0.5410 - val_loss: 0.1374\n",
      "Epoch 3/10\n",
      "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4958 - loss: 0.1531 - val_accuracy: 0.5395 - val_loss: 0.1333\n",
      "Epoch 4/10\n",
      "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5022 - loss: 0.1487 - val_accuracy: 0.5519 - val_loss: 0.1311\n",
      "Epoch 5/10\n",
      "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5160 - loss: 0.1432 - val_accuracy: 0.5559 - val_loss: 0.1279\n",
      "Epoch 6/10\n",
      "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5340 - loss: 0.1400 - val_accuracy: 0.5565 - val_loss: 0.1285\n",
      "Epoch 7/10\n",
      "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5360 - loss: 0.1364 - val_accuracy: 0.5750 - val_loss: 0.1262\n",
      "Epoch 8/10\n",
      "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5400 - loss: 0.1359 - val_accuracy: 0.5717 - val_loss: 0.1238\n",
      "Epoch 9/10\n",
      "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5421 - loss: 0.1352 - val_accuracy: 0.5626 - val_loss: 0.1242\n",
      "Epoch 10/10\n",
      "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5511 - loss: 0.1330 - val_accuracy: 0.5896 - val_loss: 0.1221\n",
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 627us/step - accuracy: 0.5929 - loss: 0.1205\n",
      "Loss: 0.12206480652093887, Accuracy: 0.5896111726760864\n"
     ]
    }
   ],
   "source": [
    "\n",
    "save_path = \"mlflow_artifacts\"\n",
    "\n",
    "# Charge le modèle Word2Vec correctement\n",
    "word2vec_model = Word2Vec.load(\"mlflow_artifacts/word2vec_model.model\")\n",
    "\n",
    "# Modèle Word2Vec\n",
    "X_train_w2v, X_test_w2v, y_train_w2v, y_test_w2v = train_test_split(X_word2vec, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model_word2vec = build_model(input_shape=300, output_shape= y_train_w2v.shape[1])\n",
    "\n",
    "# Entraînement et évaluation du modèle Word2Vec\n",
    "history_word2vec = train_model(model_word2vec, X_train_w2v, y_train_w2v, X_test_w2v, y_test_w2v)\n",
    "loss_word2vec, accuracy_word2vec = evaluate_model(model_word2vec, X_test_w2v, y_test_w2v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "2024/10/12 19:51:39 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2024/10/12 19:51:44 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/10/12 19:51:48 INFO mlflow.tracking._tracking_service.client: 🏃 View run Word2Vec Model at: https://mlflowp51-975919512217.us-central1.run.app/#/experiments/1/runs/973cbf58b07a4f5bba9262a8cf6cdd62.\n",
      "2024/10/12 19:51:48 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: https://mlflowp51-975919512217.us-central1.run.app/#/experiments/1.\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(run_name=\"Word2Vec Model\"):\n",
    "    mlflow.log_param(\"mlflow_artifacts\", \"Word2Vec\")\n",
    "    mlflow.log_metric(\"loss\", loss_word2vec)\n",
    "    mlflow.log_metric(\"accuracy\", accuracy_word2vec)\n",
    "\n",
    "    # Sauvegarde du modèle en .h5\n",
    "    model_word2vec_path = os.path.join(\"mlflow_artifacts\", 'word2vec_model.h5')\n",
    "    model_word2vec.save(model_word2vec_path)\n",
    "    \n",
    "    # Suivi dans MLflow\n",
    "    mlflow.keras.log_model(model=model_word2vec, artifact_path=\"word2vec_model\")\n",
    "    mlflow.log_artifact(model_word2vec_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588us/step - accuracy: 0.2050 - loss: 0.4720\n",
      "Loss: 0.4719560742378235, Accuracy: 0.20413123071193695\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Modèle Universal Sentence Encoder (USE)\n",
    "X_train_use, X_test_use, y_train_use, y_test_use = train_test_split(X_use_np, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Charge le modèle USE\n",
    "use_model = tf.keras.models.load_model(\"mlflow_artifacts/use_model.h5\", compile=False)\n",
    "\n",
    "# Recompile le modèle avec un nouvel optimiseur\n",
    "use_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Évaluation du modèle USE (sans réentraîner)\n",
    "loss_use, accuracy_use = evaluate_model(use_model, X_test_use, y_test_use)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "2024/10/12 19:51:49 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2024/10/12 19:51:53 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/10/12 19:51:55 INFO mlflow.tracking._tracking_service.client: 🏃 View run USE Model at: https://mlflowp51-975919512217.us-central1.run.app/#/experiments/1/runs/2987612a9e9e4347ae90b4b3ba26d355.\n",
      "2024/10/12 19:51:55 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: https://mlflowp51-975919512217.us-central1.run.app/#/experiments/1.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Suivi dans MLflow\n",
    "with mlflow.start_run(run_name=\"USE Model\"):\n",
    "    mlflow.log_param(\"model\", \"USE (Chargé et réévalué)\")\n",
    "    mlflow.log_metric(\"loss\", loss_use)\n",
    "    mlflow.log_metric(\"accuracy\", accuracy_use)\n",
    "\n",
    "    # Sauvegarde du modèle en .h5\n",
    "    model_use_path = os.path.join(\"mlflow_artifacts\", 'use_model.h5')\n",
    "    use_model.save(model_use_path)\n",
    "    \n",
    "    # Suivi dans MLflow\n",
    "    mlflow.keras.log_model(model=use_model, artifact_path=\"use_model\")\n",
    "    mlflow.log_artifact(model_use_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_tags(model, vector, top_tags, threshold=0.01):\n",
    "    predictions = model.predict(vector)\n",
    "\n",
    "    # Associe les tags avec les probabilités\n",
    "    tag_probabilities = [(top_tags[i], float(predictions[0][i])) for i in range(len(top_tags))]\n",
    "    \n",
    "    # Trie les tags par probabilité décroissante\n",
    "    sorted_tag_probabilities = sorted(tag_probabilities, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Applique le seuil de probabilité pour filtrer les tags\n",
    "    predicted_tags = [tag for tag, prob in sorted_tag_probabilities if prob >= threshold]\n",
    "    \n",
    "    logging.info(f\"Tags triés par probabilité décroissante: {sorted_tag_probabilities}\")\n",
    "    \n",
    "    return predicted_tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "BoW+SVD Model - Suggested Tags: ['python', 'python-3.x', 'amazon-web-services', 'javascript', 'azure', 'java', 'android']\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Word2Vec Model - Suggested Tags: ['c#', 'javascript', 'next.js', 'reactjs', 'node.js', 'angular', 'typescript']\n",
      "WARNING:tensorflow:From c:\\Users\\leenc\\Documents\\openclassrooms\\p5\\.venv\\Lib\\site-packages\\tensorflow_hub\\resolver.py:120: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\leenc\\Documents\\openclassrooms\\p5\\.venv\\Lib\\site-packages\\tensorflow_hub\\resolver.py:120: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\leenc\\Documents\\openclassrooms\\p5\\.venv\\Lib\\site-packages\\tensorflow_hub\\module_v2.py:126: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\leenc\\Documents\\openclassrooms\\p5\\.venv\\Lib\\site-packages\\tensorflow_hub\\module_v2.py:126: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\leenc\\Documents\\openclassrooms\\p5\\.venv\\Lib\\site-packages\\tf_keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\leenc\\Documents\\openclassrooms\\p5\\.venv\\Lib\\site-packages\\tf_keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "USE Model - Suggested Tags: ['python', 'azure', 'react-native', 'node.js', 'docker', 'reactjs', 'c#', 'java', 'next.js', 'angular', 'flutter', 'css', 'typescript', 'kotlin', 'javascript', 'amazon-web-services', 'ios', 'android', 'spring-boot', 'python-3.x']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Prédiction avec BoW + SVD\n",
    "new_question_text = \"python\"\n",
    "new_question_vector_bow = transform_text_to_bow(new_question_text, vectorizer, svd)\n",
    "predicted_tags_bow_svd = predict_tags(model_bow_svd, new_question_vector_bow, top_tags)\n",
    "print(\"BoW+SVD Model - Suggested Tags:\", predicted_tags_bow_svd)\n",
    "\n",
    "# Prédiction avec Word2Vec\n",
    "new_question_text_w2v = \"javascript tutorial\"\n",
    "new_question_vector_w2v = transform_text_to_word2vec(new_question_text_w2v, word2vec_model)\n",
    "predicted_tags_w2v = predict_tags(model_word2vec, new_question_vector_w2v, top_tags)\n",
    "print(\"Word2Vec Model - Suggested Tags:\", predicted_tags_w2v)\n",
    "\n",
    "# Prédiction avec USE\n",
    "new_question_text_use = \"how to learn machine learning\"\n",
    "new_question_vector_use = transform_text_to_use(new_question_text_use)\n",
    "predicted_tags_use = predict_tags(use_model, new_question_vector_use, top_tags)\n",
    "print(\"USE Model - Suggested Tags:\", predicted_tags_use)\n",
    "\n",
    "# Chemin global pour sauvegarder les artefacts des modèles\n",
    "save_path = '../mlruns/artifacts'\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "# Sauvegarde des modèles et des artefacts\n",
    "with open(os.path.join(save_path, 'X_use_embeddings.pkl'), 'wb') as f:\n",
    "    joblib.dump(X_use_np, f)\n",
    "mlflow.log_artifact(os.path.join(save_path, 'X_use_embeddings.pkl'))\n",
    "\n",
    "with open(os.path.join(save_path, 'X_word2vec.pkl'), 'wb') as f:\n",
    "    joblib.dump(X_word2vec, f)\n",
    "mlflow.log_artifact(os.path.join(save_path, 'X_word2vec.pkl'))\n",
    "\n",
    "with open(os.path.join(save_path, 'X_reduced.pkl'), 'wb') as f:\n",
    "    joblib.dump(X_reduced, f)\n",
    "mlflow.log_artifact(os.path.join(save_path, 'X_reduced.pkl'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
